{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc5e04a8",
      "metadata": {
        "id": "fc5e04a8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import time\n",
        "import heapq\n",
        "import random\n",
        "import json\n",
        "import zipfile\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83583a5a",
      "metadata": {
        "id": "83583a5a"
      },
      "outputs": [],
      "source": [
        "# Upload maze zip\n",
        "uploaded = files.upload()\n",
        "for fname in uploaded:\n",
        "    with zipfile.ZipFile(io.BytesIO(uploaded[fname])) as zip_ref:\n",
        "        zip_ref.extractall(\"imperfect_maze\")\n",
        "\n",
        "input_dir = \"imperfect_maze/imperfect_maze\"\n",
        "maze_files = [os.path.join(input_dir, f) for f in sorted(os.listdir(input_dir)) if f.endswith(\".txt\")]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbed072b",
      "metadata": {
        "id": "bbed072b"
      },
      "outputs": [],
      "source": [
        "# Split maze files into training and testing sets\n",
        "def split_mazes(maze_files, train_frac=0.2, seed=42):\n",
        "    random.seed(seed)\n",
        "    random.shuffle(maze_files)\n",
        "    split = int(len(maze_files) * train_frac)\n",
        "    return maze_files[:split], maze_files[split:]\n",
        "\n",
        "train_mazes, test_mazes = split_mazes(maze_files)\n",
        "print(f\"{len(train_mazes)} training mazes, {len(test_mazes)} testing mazes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d2392c",
      "metadata": {
        "id": "82d2392c"
      },
      "outputs": [],
      "source": [
        "def load_maze(path):\n",
        "    return np.loadtxt(path, dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def q_heuristic(state):\n",
        "    return -max(Q.get(state, {}).values(), default=0)\n",
        "\n",
        "def manhattan(a, b):\n",
        "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
        "\n",
        "def manhattan_heuristic(state):\n",
        "    return manhattan(state, goal)\n",
        "\n",
        "def euclidean_heuristic(state):\n",
        "    return ((state[0] - goal[0]) ** 2 + (state[1] - goal[1]) ** 2) ** 0.5"
      ],
      "metadata": {
        "id": "9scyJfMFSp1O"
      },
      "id": "9scyJfMFSp1O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32c43c0c",
      "metadata": {
        "id": "32c43c0c"
      },
      "outputs": [],
      "source": [
        "class TabularQLearning:\n",
        "    def __init__(self, actions, discount=1.0, explorationProb=0.2, initialQ=0.0, step_size=0.5):\n",
        "        self.Q = {}\n",
        "        self.actions = actions\n",
        "        self.discount = discount\n",
        "        self.explorationProb = explorationProb\n",
        "        self.initialQ = initialQ\n",
        "        self.step_size = step_size\n",
        "\n",
        "    def getQ(self, state, action):\n",
        "        return self.Q.get(state, {}).get(action, self.initialQ)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if random.random() < self.explorationProb:\n",
        "            return random.choice(self.actions)\n",
        "        qs = [(a, self.getQ(state, a)) for a in self.actions]\n",
        "        maxQ = max(qs, key=lambda x: x[1])[1]\n",
        "        best_actions = [a for a, q in qs if q == maxQ]\n",
        "        return random.choice(best_actions)\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        oldQ = self.getQ(state, action)\n",
        "        max_future_q = max([self.getQ(next_state, a) for a in self.actions], default=0)\n",
        "        target = reward + self.discount * max_future_q\n",
        "        newQ = oldQ + self.step_size * (target - oldQ)\n",
        "        if state not in self.Q:\n",
        "            self.Q[state] = {}\n",
        "        self.Q[state][action] = newQ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb65d22",
      "metadata": {
        "id": "aeb65d22"
      },
      "outputs": [],
      "source": [
        "def astar(maze, start, goal, heuristic):\n",
        "    frontier = []\n",
        "    heapq.heappush(frontier, (0, start))\n",
        "    came_from = {start: None}\n",
        "    cost_so_far = {start: 0}\n",
        "\n",
        "    while frontier:\n",
        "        _, current = heapq.heappop(frontier)\n",
        "        if current == goal:\n",
        "            break\n",
        "        for dr, dc in [(0, 1), (0, -1), (1, 0), (-1, 0)]:\n",
        "            next_state = (current[0] + dr, current[1] + dc)\n",
        "            if (\n",
        "                0 <= next_state[0] < maze.shape[0]\n",
        "                and 0 <= next_state[1] < maze.shape[1]\n",
        "                and maze[next_state] == 0\n",
        "            ):\n",
        "                new_cost = cost_so_far[current] + 1\n",
        "                if next_state not in cost_so_far or new_cost < cost_so_far[next_state]:\n",
        "                    cost_so_far[next_state] = new_cost\n",
        "                    priority = new_cost + heuristic(next_state)\n",
        "                    heapq.heappush(frontier, (priority, next_state))\n",
        "                    came_from[next_state] = current\n",
        "    return came_from, cost_so_far\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "519aa6e2",
      "metadata": {
        "id": "519aa6e2"
      },
      "outputs": [],
      "source": [
        "def train_q_learning_reversed(maze, goal, actions,\n",
        "                                      discount, explorationProb, step_size,\n",
        "                                      num_sample_starts, step_multiplier):\n",
        "    q = TabularQLearning(actions, discount=discount,\n",
        "                         explorationProb=explorationProb,\n",
        "                         step_size=step_size)\n",
        "    height, width = maze.shape\n",
        "    max_steps = step_multiplier * (height + width)\n",
        "\n",
        "    def is_valid(pos):\n",
        "        r, c = pos\n",
        "        return 0 <= r < height and 0 <= c < width and maze[r, c] == 0\n",
        "\n",
        "    free_cells = [tuple(cell) for cell in np.argwhere(maze == 0)]\n",
        "    sample_starts = random.sample(free_cells, min(num_sample_starts, len(free_cells)))\n",
        "\n",
        "    episodes = 500\n",
        "    for ep in range(episodes):\n",
        "        state = goal\n",
        "        for _ in range(max_steps):\n",
        "            action = q.choose_action(state)\n",
        "            next_state = (state[0] + action[0], state[1] + action[1])\n",
        "            if not is_valid(next_state):\n",
        "                continue\n",
        "            reward = 0 if next_state in sample_starts else -1\n",
        "            q.update(state, action, reward, next_state)\n",
        "            state = next_state\n",
        "    return q.Q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd67ccfb",
      "metadata": {
        "id": "dd67ccfb"
      },
      "outputs": [],
      "source": [
        "def evaluate_runtime(config, maze, start, goal, actions):\n",
        "    Q = train_q_learning_reversed(\n",
        "        maze, goal, actions,\n",
        "        discount=config[\"discount\"],\n",
        "        explorationProb=config[\"explorationProb\"],\n",
        "        step_size=config[\"step_size\"],\n",
        "        num_sample_starts=config[\"num_sample_starts\"],\n",
        "        step_multiplier=config[\"step_multiplier\"]\n",
        "    )\n",
        "\n",
        "    def q_heuristic(state):\n",
        "        return -max(Q.get(state, {}).values(), default=0)\n",
        "\n",
        "    start_time = time.time()\n",
        "    came_from, cost = astar(maze, start, goal, q_heuristic)\n",
        "    return time.time() - start_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88d25bd7",
      "metadata": {
        "id": "88d25bd7"
      },
      "outputs": [],
      "source": [
        "def run_single_map_search(path, actions, n_trials=30):\n",
        "    maze = load_maze(path)\n",
        "    free_cells = list(zip(*np.where(maze == 0)))\n",
        "    if len(free_cells) < 2:\n",
        "        return None\n",
        "    start = free_cells[0]\n",
        "    goal = free_cells[-1]\n",
        "\n",
        "    result = []\n",
        "    for _ in range(n_trials):\n",
        "        config = {\n",
        "            \"discount\": round(random.uniform(0.8, 1.0), 2),\n",
        "            \"explorationProb\": round(random.uniform(0.1, 0.7), 2),\n",
        "            \"step_size\": round(random.uniform(0.1, 0.9), 2),\n",
        "            \"num_sample_starts\": random.randint(3, 20),\n",
        "            \"step_multiplier\": random.randint(5, 20)\n",
        "        }\n",
        "        try:\n",
        "            runtime = evaluate_runtime(config, maze, start, goal, actions)\n",
        "            config[\"runtime\"] = runtime\n",
        "            config[\"maze\"] = os.path.basename(path)\n",
        "            result.append(config)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed on {path}: {e}\")\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31e27bea",
      "metadata": {
        "id": "31e27bea"
      },
      "outputs": [],
      "source": [
        "def run_hyperparameter_search(train_mazes, n_maps=30, n_trials_per_map=30):\n",
        "    selected_paths = random.sample(maze_files, min(n_maps, len(maze_files)))\n",
        "    actions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
        "    all_results = []\n",
        "\n",
        "    for map_idx, path in enumerate(selected_paths):\n",
        "        print(f\"\\n Running map {map_idx + 1}/{len(selected_paths)}: {os.path.basename(path)}\")\n",
        "        maze = load_maze(path)\n",
        "        free_cells = list(zip(*np.where(maze == 0)))\n",
        "        if len(free_cells) < 2:\n",
        "            print(\"Skipping map due to insufficient free space.\")\n",
        "            continue\n",
        "        start = free_cells[0]\n",
        "        goal = free_cells[-1]\n",
        "\n",
        "        for trial in range(n_trials_per_map):\n",
        "            config = {\n",
        "                \"discount\": round(random.uniform(0.8, 1.0), 2),\n",
        "                \"explorationProb\": round(random.uniform(0.1, 0.7), 2),\n",
        "                \"step_size\": round(random.uniform(0.1, 0.9), 2),\n",
        "                \"num_sample_starts\": random.randint(3, 20),\n",
        "                \"step_multiplier\": random.randint(5, 20)\n",
        "            }\n",
        "            try:\n",
        "                print(f\"Trial {trial + 1}/{n_trials_per_map}\", end=\"\\\\r\")\n",
        "                runtime = evaluate_runtime(config, maze, start, goal, actions)\n",
        "                config[\"runtime\"] = runtime\n",
        "                config[\"maze\"] = os.path.basename(path)\n",
        "                all_results.append(config)\n",
        "            except Exception as e:\n",
        "                print(f\"Trial {trial + 1} failed: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv(\"hyperparameter_results.csv\", index=False)\n",
        "    with open(\"hyperparameter_results.json\", \"w\") as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc71a0f",
      "metadata": {
        "id": "8cc71a0f"
      },
      "outputs": [],
      "source": [
        "results_df = run_hyperparameter_search(\n",
        "    train_mazes,\n",
        "    n_maps=30,\n",
        "    n_trials_per_map=30\n",
        ")\n",
        "results_df.head()\n",
        "# Training time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea01622",
      "metadata": {
        "id": "0ea01622"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "# Hardcoded best config\n",
        "best_config = {\n",
        "    \"discount\": 0.92,\n",
        "    \"explorationProb\": 0.49,\n",
        "    \"step_size\": 0.65,\n",
        "    \"num_sample_starts\": 3,\n",
        "    \"step_multiplier\": 10\n",
        "}\n",
        "actions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
        "\n",
        "for i, path in enumerate(test_mazes):\n",
        "    maze = load_maze(path)\n",
        "    free_cells = list(zip(*np.where(maze == 0)))\n",
        "    if len(free_cells) < 4:\n",
        "        print(\"  Skipped (not enough free cells)\")\n",
        "        continue\n",
        "\n",
        "    goal = free_cells[-1]\n",
        "    sample_starts = random.sample(free_cells, 3)\n",
        "\n",
        "    # Train Q-learning once\n",
        "    Q = train_q_learning_reversed(\n",
        "        maze, goal, actions,\n",
        "        discount=best_config[\"discount\"],\n",
        "        explorationProb=best_config[\"explorationProb\"],\n",
        "        step_size=best_config[\"step_size\"],\n",
        "        num_sample_starts=best_config[\"num_sample_starts\"],\n",
        "        step_multiplier=best_config[\"step_multiplier\"]\n",
        "    )\n",
        "\n",
        "    heuristics = {\n",
        "        \"Manhattan\": manhattan_heuristic,\n",
        "        \"Euclidean\": euclidean_heuristic,\n",
        "        \"Q-learned\": q_heuristic\n",
        "    }\n",
        "\n",
        "    for name, heuristic in heuristics.items():\n",
        "        total_runtime = 0\n",
        "        total_path_length = 0\n",
        "        total_nodes_expanded = 0\n",
        "\n",
        "        for start in sample_starts:\n",
        "            start_time = time.time()\n",
        "            came_from, cost = astar(maze, start, goal, heuristic)\n",
        "            runtime = time.time() - start_time\n",
        "            path_length = cost.get(goal, float('inf'))\n",
        "            nodes_expanded = len(cost)\n",
        "\n",
        "            total_runtime += runtime\n",
        "            total_path_length += path_length\n",
        "            total_nodes_expanded += nodes_expanded\n",
        "\n",
        "        results.append({\n",
        "            \"maze\": os.path.basename(path),\n",
        "            \"heuristic\": name,\n",
        "            \"runtime\": total_runtime,\n",
        "            \"path_length\": total_path_length,\n",
        "            \"nodes_expanded\": total_nodes_expanded\n",
        "        })\n",
        "\n",
        "# Save results\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(\"final_heuristic_comparison.csv\", index=False)\n",
        "with open(\"final_heuristic_comparison.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(\"Evaluation complete. Results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b965109",
      "metadata": {
        "id": "3b965109"
      },
      "outputs": [],
      "source": [
        "def visualize_heuristics_on_sampled_paths(test_mazes, best_config, num_starts=3):\n",
        "    actions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
        "    results = []\n",
        "\n",
        "    path = random.choice(test_mazes)\n",
        "    maze = load_maze(path)\n",
        "    free_cells = list(zip(*np.where(maze == 0)))\n",
        "    if len(free_cells) < num_starts + 1:\n",
        "        print(\"Not enough free cells.\")\n",
        "        return\n",
        "\n",
        "    goal = free_cells[-1]\n",
        "    sample_starts = random.sample(free_cells, num_starts)\n",
        "\n",
        "    Q = train_q_learning_reversed(\n",
        "        maze, goal, actions,\n",
        "        discount=best_config[\"discount\"],\n",
        "        explorationProb=best_config[\"explorationProb\"],\n",
        "        step_size=best_config[\"step_size\"],\n",
        "        num_sample_starts=best_config[\"num_sample_starts\"],\n",
        "        step_multiplier=best_config[\"step_multiplier\"]\n",
        "    )\n",
        "\n",
        "    heuristics = {\n",
        "        \"Manhattan\": manhattan_heuristic,\n",
        "        \"Euclidean\": euclidean_heuristic,\n",
        "        \"Q-learned\": q_heuristic\n",
        "    }\n",
        "\n",
        "    for name, h in heuristics.items():\n",
        "        total_runtime = 0\n",
        "        path_colors = [\"red\", \"green\", \"blue\"]\n",
        "        all_paths = []\n",
        "\n",
        "        # Compute heatmap values\n",
        "        values = np.full(maze.shape, np.nan)\n",
        "        for r in range(maze.shape[0]):\n",
        "            for c in range(maze.shape[1]):\n",
        "                if maze[r, c] == 0:\n",
        "                    try:\n",
        "                        values[r, c] = h((r, c))\n",
        "                    except:\n",
        "                        values[r, c] = np.nan\n",
        "\n",
        "        for idx, start in enumerate(sample_starts):\n",
        "            start_time = time.time()\n",
        "            came_from, cost = astar(maze, start, goal, h)\n",
        "            runtime = time.time() - start_time\n",
        "            total_runtime += runtime\n",
        "\n",
        "            path_points = []\n",
        "            current = goal\n",
        "            while current in came_from and came_from[current] is not None:\n",
        "                path_points.append(current)\n",
        "                current = came_from[current]\n",
        "            if current == start:\n",
        "                path_points.append(start)\n",
        "                path_points = path_points[::-1]\n",
        "                all_paths.append((idx + 1, path_points))\n",
        "            else:\n",
        "                all_paths.append((idx + 1, []))\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.imshow(values, cmap=\"viridis\")\n",
        "        plt.title(f\"{name} Heuristic\\nTotal Runtime: {total_runtime:.4f}s\")\n",
        "        plt.colorbar()\n",
        "\n",
        "        for (label, path_points), color in zip(all_paths, path_colors):\n",
        "            if path_points:\n",
        "                y, x = zip(*path_points)\n",
        "                plt.plot(x, y, color=color, label=f\"Path {label}\")\n",
        "                plt.scatter(x[0], y[0], color=color, edgecolors='black', label=f\"Start {label}\", marker='o')\n",
        "            else:\n",
        "                print(f\"âš ï¸ Path {label} not found.\")\n",
        "\n",
        "        plt.scatter(goal[1], goal[0], c=\"white\", marker=\"X\", s=100, label=\"Goal\")\n",
        "        plt.legend()\n",
        "        plt.grid(False)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"heatmap_paths_{name.lower()}.png\")\n",
        "        plt.show()\n",
        "\n",
        "    print(f\"Done for maze: {os.path.basename(path)}\")\n",
        "\n",
        "\n",
        "\n",
        "sampled_paths = random.sample(test_mazes, 5)\n",
        "\n",
        "for i, path in enumerate(sampled_paths):\n",
        "    print(f\"\\n Running map {i+1}/5: {os.path.basename(path)}\")\n",
        "    visualize_heuristics_on_sampled_paths([path], best_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda30ea4",
      "metadata": {
        "id": "eda30ea4"
      },
      "outputs": [],
      "source": [
        "def plot_runtime_progression(results_df):\n",
        "    sorted_df = results_df.sort_values(\"runtime\").reset_index(drop=True)\n",
        "    plt.figure()\n",
        "    plt.plot(sorted_df.index, sorted_df[\"runtime\"])\n",
        "    plt.xlabel(\"Config Rank (Best to Worst)\")\n",
        "    plt.ylabel(\"A* Runtime (sec)\")\n",
        "    plt.title(\"Runtime Improvement from Tuning\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_runtime_progression(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"hyperparameter_results.csv\")\n",
        "files.download(\"hyperparameter_results.json\")\n",
        "files.download(\"final_heuristic_comparison.csv\")\n",
        "files.download(\"final_heuristic_comparison.json\")"
      ],
      "metadata": {
        "id": "I4S9G77DTnST"
      },
      "id": "I4S9G77DTnST",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"final_heuristic_comparison.csv\")\n",
        "\n",
        "# Average metrics per heuristic\n",
        "summary = df.groupby(\"heuristic\").agg({\n",
        "    \"runtime\": \"mean\",\n",
        "    \"path_length\": \"mean\",\n",
        "    \"nodes_expanded\": \"mean\"\n",
        "}).reset_index()\n",
        "\n",
        "print(\"Average Metrics by Heuristic:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "qldtVa8IdesE"
      },
      "id": "qldtVa8IdesE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract dimension from maze filename (assumes naming like 'maze407_dim142.txt')\n",
        "df[\"dimension\"] = df[\"maze\"].str.extract(r'dim(\\d+)').astype(float)\n",
        "\n",
        "# Average runtime by dimension and heuristic\n",
        "avg_time_by_dim = df.groupby([\"dimension\", \"heuristic\"])[\"runtime\"].mean().reset_index()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "for heuristic in df[\"heuristic\"].unique():\n",
        "    subset = avg_time_by_dim[avg_time_by_dim[\"heuristic\"] == heuristic]\n",
        "    plt.plot(subset[\"dimension\"], subset[\"runtime\"], label=heuristic)\n",
        "\n",
        "plt.xlabel(\"Maze Dimension\")\n",
        "plt.ylabel(\"Average A* Runtime (sec)\")\n",
        "plt.title(\"A* Runtime by Maze Dimension and Heuristic\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MMJmnwfJdjvw"
      },
      "id": "MMJmnwfJdjvw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuning_df = pd.read_csv(\"hyperparameter_results.csv\")\n",
        "\n",
        "# Sort by runtime for training curve\n",
        "sorted_tuning = tuning_df.sort_values(\"runtime\").reset_index(drop=True)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(sorted_tuning.index, sorted_tuning[\"runtime\"])\n",
        "plt.xlabel(\"Trial Index (Best to Worst)\")\n",
        "plt.ylabel(\"A* Runtime with Q-learned Heuristic\")\n",
        "plt.title(\"Q-learning Heuristic Performance over Tuning Trials\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rLp66A7neKRZ"
      },
      "id": "rLp66A7neKRZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit regressor and extract feature importances\n",
        "features = [\"discount\", \"explorationProb\", \"step_size\", \"num_sample_starts\", \"step_multiplier\"]\n",
        "X = tuning_df[features]\n",
        "y = tuning_df[\"runtime\"]\n",
        "\n",
        "model = RandomForestRegressor(random_state=0)\n",
        "model.fit(X, y)\n",
        "\n",
        "importances = model.feature_importances_\n",
        "importance_df = pd.DataFrame({\"parameter\": features, \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(importance_df.set_index(\"parameter\").T, annot=True, cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Feature Importance for Runtime Prediction\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"parameter_importance_heatmap.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SVWHMMw-eQ4D"
      },
      "id": "SVWHMMw-eQ4D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare data\n",
        "df = pd.read_csv(\"final_heuristic_comparison.csv\")\n",
        "df[\"dimension\"] = df[\"maze\"].str.extract(r'dim(\\d+)').astype(float)\n",
        "\n",
        "# Align runtimes by heuristic per maze\n",
        "pivot_df = df.pivot(index=\"maze\", columns=\"heuristic\", values=[\"runtime\", \"dimension\"])\n",
        "pivot_df.columns = ['_'.join(col).strip() for col in pivot_df.columns.values]\n",
        "pivot_df = pivot_df.dropna()\n",
        "pivot_df[\"best_traditional\"] = pivot_df[[\"runtime_Manhattan\", \"runtime_Euclidean\"]].min(axis=1)\n",
        "\n",
        "# Compute relative improvement: (traditional - qlearned) / traditional\n",
        "pivot_df[\"relative_improvement\"] = (\n",
        "    (pivot_df[\"best_traditional\"] - pivot_df[\"runtime_Q-learned\"]) / pivot_df[\"best_traditional\"]\n",
        ")\n",
        "\n",
        "pivot_df[\"dimension\"] = pivot_df[\"dimension_Q-learned\"]\n",
        "agg = pivot_df.groupby(\"dimension\")[\"relative_improvement\"].agg([\"mean\", \"count\", \"std\"])\n",
        "agg[\"sem\"] = agg[\"std\"] / agg[\"count\"]**0.5\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(agg.index, agg[\"mean\"], label=\"Avg Relative Runtime Improvement\", color='green')\n",
        "plt.fill_between(agg.index, agg[\"mean\"] - agg[\"sem\"], agg[\"mean\"] + agg[\"sem\"], color='green', alpha=0.3)\n",
        "\n",
        "plt.axhline(0, color='gray', linestyle='--')\n",
        "plt.xlabel(\"Maze Dimension\")\n",
        "plt.ylabel(\"Relative Runtime Improvement (Q - Best of M/E)\")\n",
        "plt.title(\"Q-learned Heuristic Improvement Over Traditional Heuristics\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"qlearn_vs_traditional_by_dimension.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M14GYUqhpC1d"
      },
      "id": "M14GYUqhpC1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"hyperparameter_results.csv\")\n",
        "files.download(\"hyperparameter_results.json\")\n",
        "files.download(\"final_heuristic_comparison.csv\")\n",
        "files.download(\"final_heuristic_comparison.json\")\n",
        "files.download(\"parameter_importance_heatmap.png\")\n",
        "files.download(\"qlearn_vs_traditional_by_dimension.png\")"
      ],
      "metadata": {
        "id": "ovokiPXFeR6_"
      },
      "id": "ovokiPXFeR6_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your saved results\n",
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "results_df = pd.read_csv(filename)\n",
        "\n",
        "runtimes = results_df[\"runtime\"].values\n",
        "best_so_far = [runtimes[0]]\n",
        "\n",
        "for r in runtimes[1:]:\n",
        "    best_so_far.append(min(best_so_far[-1], r))\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(best_so_far)\n",
        "plt.xlabel(\"Trial Index (Chronological)\")\n",
        "plt.ylabel(\"Best Runtime So Far (sec)\")\n",
        "plt.title(\"Cumulative Best A* Runtime Over Tuning Trials\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"cumulative_best_runtime.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YqoEr_fM7NoS"
      },
      "id": "YqoEr_fM7NoS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"dimension\"] = df[\"maze\"].str.extract(r'dim(\\d+)').astype(int)\n",
        "\n",
        "grouped = df.groupby([\"heuristic\", \"dimension\"]).agg({\n",
        "    \"runtime\": \"mean\",\n",
        "    \"path_length\": \"mean\",\n",
        "    \"nodes_expanded\": \"mean\"\n",
        "}).reset_index()\n",
        "\n",
        "heuristics = grouped[\"heuristic\"].unique()\n",
        "tables = {}\n",
        "for h in heuristics:\n",
        "    table = grouped[grouped[\"heuristic\"] == h].drop(columns=\"heuristic\").sort_values(\"dimension\")\n",
        "    tables[h] = table\n",
        "    print(f\"\\\\nðŸ“Š Average Metrics per Dimension for {h} Heuristic:\")\n",
        "    display(table)\n",
        "for h, table in tables.items():\n",
        "    table.to_csv(f\"{h.lower()}_summary_by_dimension.csv\", index=False)"
      ],
      "metadata": {
        "id": "FH7bft5WA-FP"
      },
      "id": "FH7bft5WA-FP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}